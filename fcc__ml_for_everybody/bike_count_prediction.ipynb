{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Source: Data Source :http://data.seoul.go.kr/\n",
    "SOUTH KOREA PUBLIC HOLIDAYS. URL: publicholidays.go.kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"~/Code/1_Learn/study__MachineLearning/fcc__ml_for_everybody/SeoulBikeData.csv\"\n",
    "\n",
    "# We don't need this since the CSV file already has a header row\n",
    "# DATASET_COLS = [\n",
    "#     \"bike_count\",\n",
    "#     \"hour\",\n",
    "#     \"temp\",\n",
    "#     \"humidity\",\n",
    "#     \"wind\",\n",
    "#     \"visibility\",\n",
    "#     \"dew_pt_temp\",\n",
    "# ]\n",
    "Y_LABEL = \"bike_count\"\n",
    "df = pd.read_csv(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "\n",
    "# To transform a column to something numeric.\n",
    "# In this case, we are transforming values for \"functional\" to 1 (for 'Yes' values)\n",
    "# or  0 (for 'No' values)\n",
    "df[\"functional\"] = (df[\"functional\"] == \"Yes\").astype(int)\n",
    "\n",
    "# The video didn't do this, but we will (for fun!)\n",
    "df[\"holiday\"] = (df[\"holiday\"] == \"Holiday\").astype(int)\n",
    "\n",
    "print(f\"Original size: {df.size}\")\n",
    "\n",
    "# Limit the data set to only data during a specific hour\n",
    "# This is what was done\n",
    "# in the video but for our actual model, we _may_ want to use the hour as an additional\n",
    "# feature when training our model.\n",
    "df = df[df[\"hour\"] == 12] # Only get data from 12:00 (Noon)\n",
    "df = df.drop([\"Date\", \"hour\"], axis=1) # Drop the 'hour' column\n",
    "\n",
    "print(f\"Final size: {df.size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Peek at our cleaned data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "# Explore our dataset by plotting them\n",
    "for label in df.columns[\n",
    "    1:\n",
    "]:  # All the features / all columns except the first one (which is the target/\"y-label\"/ bike count)\n",
    "    # To explore how a specific label/feature affect the bike count\n",
    "    plt.scatter(x=df[label], y=df[Y_LABEL])  # TODO CONFIRM KEYWORD ARGUMENTS\n",
    "    plt.title(label)\n",
    "    plt.ylabel(\"Bike Count at Noon\")\n",
    "    plt.xlabel(label)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the features/labels that do not seem to matter.\n",
    "df = df.drop([\"wind\", \"visibility\", \"functional\"], axis=1)\n",
    "\n",
    "# Let's get rid of multi-values/text values for now:\n",
    "df = df.drop([\"seasons\"], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data to 3 data sets: training (60%) / validation (20%) / test (20%)\n",
    "# We use df.sample to ensure that the data included in the data sets are randomized\n",
    "train, val, test = np.split(df.sample(frac=1), [int(0.6 * len(df)), int(0.8 * len(df))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(dataframe, y_label, x_labels=None):\n",
    "    \"\"\"Get x (features) data and y (target) from the dataframe.\"\"\"\n",
    "    dataframe = copy.deepcopy(dataframe)\n",
    "    if x_labels is None:\n",
    "        selected_features = [c for c in dataframe.columns if c != y_label]\n",
    "    # elif len(x_labels) == 1:\n",
    "        # TODO it is possible we can simplify this? to just say\n",
    "        # selected_features = x_labels. Check whether it will result to the same\n",
    "        # shape as the code we currently have.\n",
    "        # X = dataframe[x_labels[0]].values.reshape(\n",
    "        #     -1, 1\n",
    "        # )  # The reshape is to make it to a 2d array\n",
    "    else:\n",
    "        selected_features = x_labels\n",
    "\n",
    "    X = dataframe[selected_features].values\n",
    "    y = dataframe[y_label].values.reshape(-1, 1)  # The reshape is to make it a 2d array\n",
    "    data = np.hstack((X, y))\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the x (features) and y (target) values from the 3 data sets: train, validation, test\n",
    "_, X_train_temp, y_train_temp = get_xy(train, Y_LABEL, x_labels=[\"temp\"])\n",
    "_, X_val_temp, y_val_temp = get_xy(val, Y_LABEL, x_labels=[\"temp\"])\n",
    "_, X_test_temp, y_test_temp = get_xy(test, Y_LABEL, x_labels=[\"temp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a LinearRegression model\n",
    "temp_reg = LinearRegression()\n",
    "temp_reg.fit(X_train_temp, y_train_temp)\n",
    "\n",
    "# Output the coefficient and intercept. These are the constants that resulted from\n",
    "# the training.\n",
    "print(temp_reg.coef_, temp_reg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the r^2 score; The higher the number, the higher the correlation between\n",
    "# the feature and the target.\n",
    "temp_reg.score(X_test_temp, y_test_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the model\n",
    "plt.scatter(X_train_temp, y_train_temp, label=\"Data\", color=\"blue\")\n",
    "# The temp(erature) data goes from -20 to 40; Get 100 values from that range.\n",
    "# TODO you can verify that temperature data is within the range [-20, 40] by getting\n",
    "# min and max of the temp values.\n",
    "x = tf.linspace(-20, 40, 100)\n",
    "# Turn the data into an array and reshape it to a 2d array.\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "plt.plot(x, temp_reg.predict(x), label=\"Fit\", color=\"red\", linewidth=3)\n",
    "plt.legend()\n",
    "plt.title(\"Bikes vs Temp\")\n",
    "plt.ylabel(\"Number of bikes\")\n",
    "plt.xlabel(\"Temp\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
